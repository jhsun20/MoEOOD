# Main configuration file for GNN experiments

# Experiment settings
experiment:
  name: "moe_sst2" # baseline_gnn or moe_nogate_noaug or moe_noaug
  device: "cuda"  # or "cpu"
  seeds: [1, 2, 3, 4, 5]  # Add more seeds as needed
  hyper_search:
    enable: false
    n_trials_1: 10
    test_after: true

# Dataset configuration
dataset:
  dataset_name: "GOODSST2"
  task_type: "graph_classification"
  path: "./datasets"
  shift_type: "covariate"
  batch_size: 64
  num_workers: 4
  domain: 'length'

# Model configuration
model:
  type: "moe"
  hidden_dim: 300
  num_layers: 3
  dropout: 0.5
  global_pooling: "sum"
  weight_reg: 1.0
  weight_ce: 1.0
  weight_div: 1.0
  weight_load: 0.5
  num_experts: 1
  aggregation: "weighted_mean"
  rho_edge: 0.2

# Training configuration
training:
  epochs: 50
  lr: 0.001
  weight_decay: 0.0001
  early_stopping:
    patience: 10
    min_delta: 0.001

# Gating module configuration
gate:
  activation: "entmax"
  entmax_alpha: 1.38
  train_after: 10
  finetune_epochs: 0